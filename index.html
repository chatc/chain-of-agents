<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Chain-of-Agents, a training-free, task-agnostic, highly interpretable framework for Long Context.">
  <meta name="keywords" content="Chain-of-Agents, Long Context, Large Language Model, Multi-agent Collaboration">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Chain of Agents: Large Language Models Collaborating on Long-Context Tasks</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://arxiv.org/pdf/2110.10150">
            SummN
          </a>
          <a class="navbar-item" href="https://arxiv.org/pdf/2110.08168">
            DYLE
          </a>
          <a class="navbar-item" href="https://arxiv.org/pdf/2109.04609">
            Long Dialogue Summ
          </a>
          
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Chain of Agents: Large Language Models Collaborating on Long-Context Tasks</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yuszh.com/">Yusen Zhang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://research.google/people/ruoxi-sun/">Ruoxi Sun</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://research.google/people/yanfei-chen/">Yanfei Chen</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://tomas.pfister.fi/">Tomas Pfister</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://ryanzhumich.github.io/">Rui Zhang</a><sup>*1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.sercanarik.com/">Sercan Ö. Arık</a><sup>*2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Penn State University,</span>
            <span class="author-block"><sup>2</sup>Google Cloud AI Research</span>
            <br>
            <span class="author-block"><sup>*</sup>Last Authors</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2406.02818"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Arxiv Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2406.02818"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/CoA.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Chain-of-Agents is a training-free, task-agnostic, highly interpretable framework for Long Context.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          
          <p>Addressing the challenge of effectively processing long contexts has become a critical issue for Large Language Models (LLMs). 
          Two common strategies have emerged: 1) reducing the input length, such as retrieving relevant chunks by Retrieval-Augmented Generation (RAG), 
          and 2) expanding the context window limit of LLMs. However, both strategies have drawbacks: input reduction has no guarantee of covering 
          the part with needed information, while window extension struggles with focusing on the pertinent information for solving the task. 
          To mitigate these limitations, we propose Chain-of-Agents (CoA), a novel framework that harnesses multi-agent collaboration through natural 
          language to enable information aggregation and context reasoning across various LLMs over long-context tasks. 
          CoA consists of multiple worker agents who sequentially communicate to handle different segmented portions of the text, followed by 
          a manager agent who synthesizes these contributions into a coherent final output. 
          CoA processes the entire input by interleaving reading and reasoning, and it mitigates long context focus issues by assigning each agent 
          a short context. We perform comprehensive evaluation of CoA on a wide range of long-context tasks in question answering, summarization, 
          and code completion, demonstrating significant improvements by up to 10% over strong baselines of RAG, Full-Context, and multi-agent LLMs.</p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper Figure 1 -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overall Structure of Chain-of-Agent</h2>
        <img src="./static/images/coa.PNG"
             class="interpolation-image"
             alt="Overall Structure of Chain-of-Agent."/>
        <p>It consists of multiple worker agents who sequentially communicate to handle different segmented portions of the text, 
        followed by a manager agent who synthesizes these contributions into a coherent final output.</p>
      </div>
    </div>
    <!--/ Paper Figure 1 -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Comapre With RAG. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Compare with RAG</h2>
          <p>
            CoA Improvement is More Obvious When RAG Fails to Retrieve Gold Answer. Each point indicates a different retrieval quality (lower is better).
          </p>
          <img src="./static/images/rag_plot.PNG"
             class="interpolation-image"
             alt="Compare with RAG."/>
        </div>
      </div>
      <!--/ Comapre With RAG. -->

      <!-- Compare with Long LLMs -->
      <div class="column">
        <h2 class="title is-3">Compare with Long LLM</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
               CoA Improvement is More Obvious When Long Context Models Meet Longer Inputs. Each bar indicates the samples with a different source length.
            </p>
            <img src="./static/images/long_haiku.PNG"
               class="interpolation-image"
               alt="Compare with Long LLMs."/>
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->

    <!-- Case Study -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Case Study</h2>

        <!-- RAG -->
        <h3 class="title is-4">Multi-agent Collaboration in CoA Enables Complex Reasoning over Long Context</h3>
        <div class="content has-text-justified">
          <p>
            The figure displays a sample prediction from HotpotQA. To find the correct answer, RAG retrieves text
           chunks with high semantic similarity with the query. However, conducting multi-hop reasoning is
           challenging as the critical first-hop answer often lacks semantic relevance to the query. In contrast,
           CoA operates differently: the first agent explores related topics without knowing the query’s answer,
           aiding subsequent inference. The second agent, also unaware of the answer, broadens the topic
           scope by incorporating new information. The third agent finally discovers the answer, synthesizing
           information from earlier agents and new data to complete the reasoning chain. This collaborative
           approach highlights CoA’s ability to facilitate complex reasoning across long context tasks.
          </p>
        </div>
        <img src="./static/images/rag.jfif"
               class="interpolation-image"
               alt="A case study."/>

        <!--/ Interpolating. -->

      </div>
    </div>
    <!--/ Animation. -->




  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{zhang2024chain,
  author    = {Zhang, Yusen and Sun, Ruoxi and Chen, Yanfei and Pfister, Tomas and Zhang, Rui and Arık, Sercan Ö.},
  title     = {Chain of Agents: Large Language Models Collaborating on Long-Context Tasks},
  journal   = {arXiv:2406.02818},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      Penn State NLP Lab 
      <a class="icon-link"
         href="https://nlp.psu.edu/">
        <i class="fas fa-home"></i>
      </a>
      <a class="icon-link" href="https://github.com/psunlpgroup" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
      & Google Cloud AI Research 
      <a class="icon-link"
         href="https://research.google/teams/cloud-ai/">
        <i class="fas fa-home"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is made by Yusen Zhang, adapted from <a href="https://nerfies.github.io/">Nerfies</a>. This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
           
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
